airflow-worker-1  | [[34m2025-03-28T05:48:26.812+0000[0m] {[34mconfiguration.py:[0m2049} INFO[0m - Creating new FAB webserver config file in: /opt/airflow/webserver_config.py[0m
airflow-worker-1  | [2025-03-28 05:48:33 +0000] [14] [INFO] Starting gunicorn 23.0.0
airflow-worker-1  | [2025-03-28 05:48:33 +0000] [14] [INFO] Listening at: http://[::]:8793 (14)
airflow-worker-1  | [2025-03-28 05:48:33 +0000] [14] [INFO] Using worker: sync
airflow-worker-1  | [2025-03-28 05:48:33 +0000] [15] [INFO] Booting worker with pid: 15
airflow-worker-1  | [2025-03-28 05:48:33 +0000] [16] [INFO] Booting worker with pid: 16
airflow-worker-1  |  
airflow-worker-1  |  -------------- celery@f88e86835098 v5.4.0 (opalescent)
airflow-worker-1  | --- ***** ----- 
airflow-worker-1  | -- ******* ---- Linux-6.8.0-1021-azure-x86_64-with-glibc2.36 2025-03-28 05:48:36
airflow-worker-1  | - *** --- * --- 
airflow-worker-1  | - ** ---------- [config]
airflow-worker-1  | - ** ---------- .> app:         airflow.providers.celery.executors.celery_executor:0x7b9363b3d610
airflow-worker-1  | - ** ---------- .> transport:   redis://redis:6379/0
airflow-worker-1  | - ** ---------- .> results:     postgresql://postgres:**@postgres/aphrc
airflow-worker-1  | - *** --- * --- .> concurrency: 16 (prefork)
airflow-worker-1  | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
airflow-worker-1  | --- ***** ----- 
airflow-worker-1  |  -------------- [queues]
airflow-worker-1  |                 .> default          exchange=default(direct) key=default
airflow-worker-1  |                 
airflow-worker-1  | 
airflow-worker-1  | [tasks]
airflow-worker-1  |   . airflow.providers.celery.executors.celery_executor_utils.execute_command
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 05:48:42,242: WARNING/MainProcess] /usr/local/lib/python3.11/site-packages/celery/worker/consumer/consumer.py:508: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
airflow-worker-1  | whether broker connection retries are made during startup in Celery 6.0 and above.
airflow-worker-1  | If you wish to retain the existing behavior for retrying connections on startup,
airflow-worker-1  | you should set broker_connection_retry_on_startup to True.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 05:48:42,379: INFO/MainProcess] Connected to redis://redis:6379/0
airflow-worker-1  | [2025-03-28 05:48:42,394: WARNING/MainProcess] /usr/local/lib/python3.11/site-packages/celery/worker/consumer/consumer.py:508: CPendingDeprecationWarning: The broker_connection_retry configuration setting will no longer determine
airflow-worker-1  | whether broker connection retries are made during startup in Celery 6.0 and above.
airflow-worker-1  | If you wish to retain the existing behavior for retrying connections on startup,
airflow-worker-1  | you should set broker_connection_retry_on_startup to True.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 05:48:42,431: INFO/MainProcess] mingle: searching for neighbors
airflow-worker-1  | [2025-03-28 05:48:43,472: INFO/MainProcess] mingle: all alone
airflow-worker-1  | [2025-03-28 05:48:43,503: INFO/MainProcess] celery@f88e86835098 ready.
airflow-worker-1  | [2025-03-28 05:48:43,512: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[7f051764-0668-4c49-8d82-d8e9f10a96a1] received
airflow-worker-1  | [2025-03-28 05:48:43,517: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[ca28e7e9-155b-4a1a-96f3-23bbc9bbe731] received
airflow-worker-1  | [2025-03-28 05:48:44,078: INFO/ForkPoolWorker-15] [7f051764-0668-4c49-8d82-d8e9f10a96a1] Executing command in Celery: ['airflow', 'tasks', 'run', 'resource_summary_generator_dag', 'generate_resource_summaries', 'scheduled__2025-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/summary_dag.py']
airflow-worker-1  | [2025-03-28 05:48:44,129: INFO/ForkPoolWorker-16] [ca28e7e9-155b-4a1a-96f3-23bbc9bbe731] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'load_environment_variables', 'scheduled__2025-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:48:44,403: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/summary_dag.py
airflow-worker-1  | [2025-03-28 05:48:44,452: INFO/ForkPoolWorker-16] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:48:46,160: ERROR/ForkPoolWorker-16] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:48:46,373: INFO/ForkPoolWorker-15] Running <TaskInstance: resource_summary_generator_dag.generate_resource_summaries scheduled__2025-03-27T00:00:00+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:48:46,691: INFO/ForkPoolWorker-16] Running <TaskInstance: domain_classification_workflow.load_environment_variables scheduled__2025-03-27T00:00:00+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:48:48,320: INFO/ForkPoolWorker-16] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[ca28e7e9-155b-4a1a-96f3-23bbc9bbe731] succeeded in 4.793481288999999s: None
airflow-worker-1  | [2025-03-28 05:48:48,521: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[35f744bb-cefc-4eb9-9ce5-73ed5163b5d6] received
airflow-worker-1  | [2025-03-28 05:48:48,542: INFO/ForkPoolWorker-16] [35f744bb-cefc-4eb9-9ce5-73ed5163b5d6] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'scheduled__2025-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:48:48,700: INFO/ForkPoolWorker-16] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:48:49,363: ERROR/ForkPoolWorker-16] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:48:49,591: INFO/ForkPoolWorker-16] Running <TaskInstance: domain_classification_workflow.run_publication_classification scheduled__2025-03-27T00:00:00+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:48:50,309: INFO/ForkPoolWorker-16] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[35f744bb-cefc-4eb9-9ce5-73ed5163b5d6] succeeded in 1.7855570980000266s: None
airflow-worker-1  | [2025-03-28 05:49:11,474: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[7f051764-0668-4c49-8d82-d8e9f10a96a1] succeeded in 27.95491272800001s: None
airflow-worker-1  | [2025-03-28 05:53:50,469: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[82367dd3-2cc4-4c73-8b81-cfd05afee731] received
airflow-worker-1  | [2025-03-28 05:53:50,475: INFO/ForkPoolWorker-15] [82367dd3-2cc4-4c73-8b81-cfd05afee731] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'scheduled__2025-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:53:50,525: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:53:50,925: ERROR/ForkPoolWorker-15] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:53:51,033: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification scheduled__2025-03-27T00:00:00+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:53:51,418: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[82367dd3-2cc4-4c73-8b81-cfd05afee731] succeeded in 0.9474544949999881s: None
airflow-worker-1  | [2025-03-28 05:58:52,225: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[e0c1ad40-87c4-49c9-9d3e-be3890d299be] received
airflow-worker-1  | [2025-03-28 05:58:52,230: INFO/ForkPoolWorker-15] [e0c1ad40-87c4-49c9-9d3e-be3890d299be] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'scheduled__2025-03-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:58:52,280: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:58:52,677: ERROR/ForkPoolWorker-15] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:58:52,790: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification scheduled__2025-03-27T00:00:00+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:58:53,184: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[e0c1ad40-87c4-49c9-9d3e-be3890d299be] succeeded in 0.957379377000052s: None
airflow-worker-1  | [2025-03-28 05:58:53,794: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[d09bffd6-0043-4932-9481-7b5542c2e763] received
airflow-worker-1  | [2025-03-28 05:58:53,798: INFO/ForkPoolWorker-15] [d09bffd6-0043-4932-9481-7b5542c2e763] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'load_environment_variables', 'manual__2025-03-28T05:50:35.104954+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:58:53,853: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:58:54,279: ERROR/ForkPoolWorker-15] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:58:54,395: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.load_environment_variables manual__2025-03-28T05:50:35.104954+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:58:54,783: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[d09bffd6-0043-4932-9481-7b5542c2e763] succeeded in 0.9882385179998892s: None
airflow-worker-1  | [2025-03-28 05:58:54,950: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[cc608083-9d90-4536-99ec-06cd962e2bca] received
airflow-worker-1  | [2025-03-28 05:58:54,955: INFO/ForkPoolWorker-15] [cc608083-9d90-4536-99ec-06cd962e2bca] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T05:50:35.104954+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 05:58:55,006: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 05:58:55,435: ERROR/ForkPoolWorker-15] Could not import classification functions: cannot import name 'print_domain_structure' from 'ai_services_api.services.centralized_repository.domain_classification_service' (/app/ai_services_api/services/centralized_repository/domain_classification_service.py)
airflow-worker-1  | [2025-03-28 05:58:55,554: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T05:50:35.104954+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 05:58:55,940: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[cc608083-9d90-4536-99ec-06cd962e2bca] succeeded in 0.9887962010000138s: None
airflow-worker-1  | [2025-03-28 06:03:56,078: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[33832c96-da34-4f7c-aa5f-2e072a27d5a3] received
airflow-worker-1  | [2025-03-28 06:03:56,083: INFO/ForkPoolWorker-15] [33832c96-da34-4f7c-aa5f-2e072a27d5a3] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T05:50:35.104954+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:03:56,135: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:03:56,672: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T05:50:35.104954+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:03:57,055: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[33832c96-da34-4f7c-aa5f-2e072a27d5a3] succeeded in 0.9760931149999124s: None
airflow-worker-1  | [2025-03-28 06:08:57,451: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[de3b34c3-d3db-425c-834b-ed81f7e02efa] received
airflow-worker-1  | [2025-03-28 06:08:57,456: INFO/ForkPoolWorker-15] [de3b34c3-d3db-425c-834b-ed81f7e02efa] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T05:50:35.104954+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:08:57,507: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:08:58,022: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T05:50:35.104954+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:08:58,412: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[de3b34c3-d3db-425c-834b-ed81f7e02efa] succeeded in 0.9591640999999527s: None
airflow-worker-1  | [2025-03-28 06:08:59,404: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[8d79361b-b8c8-462e-8267-32603500871f] received
airflow-worker-1  | [2025-03-28 06:08:59,409: INFO/ForkPoolWorker-15] [8d79361b-b8c8-462e-8267-32603500871f] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T06:03:14.121672+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:08:59,462: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:08:59,968: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T06:03:14.121672+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:09:00,348: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[8d79361b-b8c8-462e-8267-32603500871f] succeeded in 0.9425402399999712s: None
airflow-worker-1  | [2025-03-28 06:14:00,539: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[8f0497ec-14b1-4010-bbfb-f1228f13b599] received
airflow-worker-1  | [2025-03-28 06:14:00,545: INFO/ForkPoolWorker-15] [8f0497ec-14b1-4010-bbfb-f1228f13b599] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T06:03:14.121672+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:14:00,609: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:14:02,501: WARNING/ForkPoolWorker-15] /usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 06:14:04,881: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[36791d6d-39c7-4b5d-a09d-95bc388f9cf3] received
airflow-worker-1  | [2025-03-28 06:14:04,888: INFO/ForkPoolWorker-16] [36791d6d-39c7-4b5d-a09d-95bc388f9cf3] Executing command in Celery: ['airflow', 'tasks', 'run', 'search_indexes_dag', 'create_faiss_search_index', 'manual__2025-03-28T06:14:04.642364+00:00', '--local', '--subdir', 'DAGS_FOLDER/indexes_dag.py']
airflow-worker-1  | [2025-03-28 06:14:04,955: INFO/ForkPoolWorker-16] Filling up the DagBag from /opt/airflow/dags/indexes_dag.py
airflow-worker-1  | [2025-03-28 06:14:05,100: INFO/ForkPoolWorker-16] Running <TaskInstance: search_indexes_dag.create_faiss_search_index manual__2025-03-28T06:14:04.642364+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:14:06,163: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T06:03:14.121672+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:14:06,364: INFO/ForkPoolWorker-16] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[36791d6d-39c7-4b5d-a09d-95bc388f9cf3] succeeded in 1.4809505540001737s: None
airflow-worker-1  | [2025-03-28 06:14:06,767: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[6d1416af-a977-4bf2-a0f9-d6c5812ec4c0] received
airflow-worker-1  | [2025-03-28 06:14:06,774: INFO/ForkPoolWorker-16] [6d1416af-a977-4bf2-a0f9-d6c5812ec4c0] Executing command in Celery: ['airflow', 'tasks', 'run', 'search_indexes_dag', 'create_redis_search_indexes', 'manual__2025-03-28T06:14:04.642364+00:00', '--local', '--subdir', 'DAGS_FOLDER/indexes_dag.py']
airflow-worker-1  | [2025-03-28 06:14:06,806: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[8f0497ec-14b1-4010-bbfb-f1228f13b599] succeeded in 6.265712573999963s: None
airflow-worker-1  | [2025-03-28 06:14:06,848: INFO/ForkPoolWorker-16] Filling up the DagBag from /opt/airflow/dags/indexes_dag.py
airflow-worker-1  | [2025-03-28 06:14:06,974: INFO/ForkPoolWorker-16] Running <TaskInstance: search_indexes_dag.create_redis_search_indexes manual__2025-03-28T06:14:04.642364+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:14:11,099: INFO/ForkPoolWorker-16] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[6d1416af-a977-4bf2-a0f9-d6c5812ec4c0] succeeded in 4.331072854000013s: None
airflow-worker-1  | [2025-03-28 06:15:11,301: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[85ca00ff-856c-4d0e-9212-849cc668646b] received
airflow-worker-1  | [2025-03-28 06:15:11,307: INFO/ForkPoolWorker-15] [85ca00ff-856c-4d0e-9212-849cc668646b] Executing command in Celery: ['airflow', 'tasks', 'run', 'search_indexes_dag', 'create_redis_search_indexes', 'manual__2025-03-28T06:14:04.642364+00:00', '--local', '--subdir', 'DAGS_FOLDER/indexes_dag.py']
airflow-worker-1  | [2025-03-28 06:15:11,365: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/indexes_dag.py
airflow-worker-1  | [2025-03-28 06:15:11,493: INFO/ForkPoolWorker-15] Running <TaskInstance: search_indexes_dag.create_redis_search_indexes manual__2025-03-28T06:14:04.642364+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:15:15,517: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[85ca00ff-856c-4d0e-9212-849cc668646b] succeeded in 4.213881709999896s: None
airflow-worker-1  | [2025-03-28 06:19:07,165: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[352cb03f-0e52-4d34-91df-ad3722099c37] received
airflow-worker-1  | [2025-03-28 06:19:07,170: INFO/ForkPoolWorker-15] [352cb03f-0e52-4d34-91df-ad3722099c37] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T06:03:14.121672+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:19:07,228: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:19:08,974: WARNING/ForkPoolWorker-15] /usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 06:19:11,866: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T06:03:14.121672+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:19:12,320: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[352cb03f-0e52-4d34-91df-ad3722099c37] succeeded in 5.153301160999945s: None
airflow-worker-1  | [2025-03-28 06:24:37,101: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[6be903f7-0045-4ba7-be78-9795d1d7b77c] received
airflow-worker-1  | [2025-03-28 06:24:37,107: INFO/ForkPoolWorker-15] [6be903f7-0045-4ba7-be78-9795d1d7b77c] Executing command in Celery: ['airflow', 'tasks', 'run', 'search_indexes_dag', 'create_faiss_search_index', 'manual__2025-03-28T06:24:36.450202+00:00', '--local', '--subdir', 'DAGS_FOLDER/indexes_dag.py']
airflow-worker-1  | [2025-03-28 06:24:37,170: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/indexes_dag.py
airflow-worker-1  | [2025-03-28 06:24:37,297: INFO/ForkPoolWorker-15] Running <TaskInstance: search_indexes_dag.create_faiss_search_index manual__2025-03-28T06:24:36.450202+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:24:38,097: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[6be903f7-0045-4ba7-be78-9795d1d7b77c] succeeded in 0.993141920999733s: None
airflow-worker-1  | [2025-03-28 06:24:38,339: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[352360b9-b9e9-4357-af3e-c3fab9f9c175] received
airflow-worker-1  | [2025-03-28 06:24:38,354: INFO/ForkPoolWorker-15] [352360b9-b9e9-4357-af3e-c3fab9f9c175] Executing command in Celery: ['airflow', 'tasks', 'run', 'search_indexes_dag', 'create_redis_search_indexes', 'manual__2025-03-28T06:24:36.450202+00:00', '--local', '--subdir', 'DAGS_FOLDER/indexes_dag.py']
airflow-worker-1  | [2025-03-28 06:24:38,474: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/indexes_dag.py
airflow-worker-1  | [2025-03-28 06:24:38,662: INFO/ForkPoolWorker-15] Running <TaskInstance: search_indexes_dag.create_redis_search_indexes manual__2025-03-28T06:24:36.450202+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:24:43,119: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[352360b9-b9e9-4357-af3e-c3fab9f9c175] succeeded in 4.777923499999815s: None
airflow-worker-1  | [2025-03-28 06:25:23,707: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[aa514870-3a19-4b1c-abf5-cd6632fecb52] received
airflow-worker-1  | [2025-03-28 06:25:23,713: INFO/ForkPoolWorker-15] [aa514870-3a19-4b1c-abf5-cd6632fecb52] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T06:25:23.435476+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:25:23,773: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:25:25,643: WARNING/ForkPoolWorker-15] /usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 06:25:28,475: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T06:25:23.435476+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:25:28,986: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[aa514870-3a19-4b1c-abf5-cd6632fecb52] succeeded in 5.2768468529998245s: None
airflow-worker-1  | [2025-03-28 06:30:29,625: INFO/MainProcess] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[0f72922f-1a35-4072-939f-78525f2f0d06] received
airflow-worker-1  | [2025-03-28 06:30:29,631: INFO/ForkPoolWorker-15] [0f72922f-1a35-4072-939f-78525f2f0d06] Executing command in Celery: ['airflow', 'tasks', 'run', 'domain_classification_workflow', 'run_publication_classification', 'manual__2025-03-28T06:25:23.435476+00:00', '--local', '--subdir', 'DAGS_FOLDER/content_tagging_dag.py']
airflow-worker-1  | [2025-03-28 06:30:29,692: INFO/ForkPoolWorker-15] Filling up the DagBag from /opt/airflow/dags/content_tagging_dag.py
airflow-worker-1  | [2025-03-28 06:30:31,762: WARNING/ForkPoolWorker-15] /usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
airflow-worker-1  |   warnings.warn(
airflow-worker-1  | 
airflow-worker-1  | [2025-03-28 06:30:34,642: INFO/ForkPoolWorker-15] Running <TaskInstance: domain_classification_workflow.run_publication_classification manual__2025-03-28T06:25:23.435476+00:00 [queued]> on host f88e86835098
airflow-worker-1  | [2025-03-28 06:30:35,121: INFO/ForkPoolWorker-15] Task airflow.providers.celery.executors.celery_executor_utils.execute_command[0f72922f-1a35-4072-939f-78525f2f0d06] succeeded in 5.495075140999688s: None
